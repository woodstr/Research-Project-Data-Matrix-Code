{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import os\n",
    "\n",
    "from pylibdmtx.pylibdmtx import encode\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms.v2.functional import adjust_brightness\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Parameters\n",
    "\n",
    "To synthesize the dataset the following parameters and amounts will be used:\n",
    "\n",
    "- 20 randomized strings in following letter (L) number (N) format:\n",
    "    - NLNLNNNNNNN + NNNN\n",
    "    - \\+ NNNN denotes the last 4 numbers in a serial number which increment by 1. Therefore this will range from 0000 to 0100 to mimic the real-world data more closely.\n",
    "- 20 configurations of shape transformations of the following types:\n",
    "    - random horizontal flip\n",
    "    - random vertical flip\n",
    "    - random rotation\n",
    "    - random affine\n",
    "    - random perspective\n",
    "- 5 different scalings between 0-1\n",
    "- 20 configurations of color transformations of the following types:\n",
    "    - color jitter\n",
    "    - random photometric distort\n",
    "    - random grayscale\n",
    "    - gaussian blur\n",
    "    - gaussian noise\n",
    "    - random invert\n",
    "    - random adjust sharpness\n",
    "\n",
    "This will lead to $20*20*5*20*2 = 80,000$ images being generated (40,000 ground truth and 40,000 noisy data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "These helpers do each individual part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_string():\n",
    "    '''\n",
    "    Generates a serial number to encode\n",
    "    \n",
    "    Serial numbers are:\n",
    "    - 11 characters long\n",
    "    - Index 0, 2, 4, 5, 6, 7, 8, 9, 10 are random digits\n",
    "    - Index 1 and 3 are uppercase letters\n",
    "    - Index 11, 12, 13, 14 are an incremental number starting from 0001\n",
    "\n",
    "    Example serial number: 4 L 4 N 0418028 0001\n",
    "    '''\n",
    "    to_encode = ''\n",
    "\n",
    "    # first 11 indexes\n",
    "    for j in range(11):\n",
    "        # 1 and 3 are uppercase\n",
    "        if j in [1, 3]:\n",
    "            to_encode += random.choice(string.ascii_uppercase)\n",
    "        else:\n",
    "            to_encode += str(random.randrange(0, 10))\n",
    "    \n",
    "    # last 4 indexes\n",
    "    end = str(random.randrange(1, 99))\n",
    "    if len(end) == 1:\n",
    "        end = '0' + end\n",
    "    elif len(end) == 2:\n",
    "        end = '00' + end\n",
    "    else:\n",
    "        end = '000' + end\n",
    "    to_encode += end\n",
    "\n",
    "    return to_encode\n",
    "\n",
    "def encode_image(to_encode):\n",
    "    '''Creates a PIL image containing DMC encoding of given string'''\n",
    "    encoded = encode(to_encode.encode('utf8'))\n",
    "    img = Image.frombytes('RGB', (encoded.width, encoded.height), encoded.pixels)\n",
    "    img = img.crop((10, 10, img.width-10, img.height-10)) # crop image to remove white borders\n",
    "    img = img.resize((img.width*10, img.height*10), Image.BILINEAR) # upscale image\n",
    "    return img\n",
    "\n",
    "def shape_transform(img):\n",
    "    '''Applies random shape transformations to image'''\n",
    "    transforms = v2.Compose([\n",
    "        v2.Pad(1500, fill=255, padding_mode='constant'),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomVerticalFlip(),\n",
    "        v2.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=Image.BILINEAR, fill=255),\n",
    "        v2.RandomRotation(random.randrange(0, 360), fill=255, interpolation=Image.BILINEAR),\n",
    "        v2.RandomAffine(degrees=0,\n",
    "                        translate=(0.2, 0.2), # random \"shift\" on x and y axis\n",
    "                        scale=(0.5, 1.5), # randomly scale image size between 0.5 and 1.5\n",
    "                        # random \"squish\" on x and y axis\n",
    "                        shear=(-random.randrange(10,20), random.randrange(10,20), -random.randrange(10,20), random.randrange(10,20)),\n",
    "                        fill=255,\n",
    "                        interpolation=Image.BILINEAR,\n",
    "                        ),\n",
    "        # v2.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=Image.BILINEAR, fill=255),\n",
    "    ])\n",
    "\n",
    "    img = transforms(img)\n",
    "    return img\n",
    "\n",
    "def brightness_transform(img, increment):\n",
    "    '''\n",
    "    Applies random brightness transformations to image\n",
    "    Incremenets by 1 initially to avoid 0 pixel values\n",
    "    Converts to int16 to avoid overflow (would make white pixels black)\n",
    "    '''\n",
    "    img = np.array(img, dtype=np.int16)\n",
    "    img = np.clip(img + increment, 0, 255)\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "def blend_texture(img, texture_path):\n",
    "    '''\n",
    "    Blends img with a random texture image from texture_path\n",
    "    takes a random crop of the texture\n",
    "    resizes texture to match img size\n",
    "    '''\n",
    "    texture = Image.open(texture_path)\n",
    "\n",
    "    # random crop with pytorch RandomCrop\n",
    "    crop_size = int(0.8 * min(texture.size)) # crop size based on texture size\n",
    "    transforms = v2.Compose([\n",
    "        v2.RandomCrop(size=(crop_size, crop_size)), # smallest resolution image is 1280 x 1024\n",
    "    ])\n",
    "    texture = transforms(texture)\n",
    "    texture = texture.resize(img.size, Image.BILINEAR)\n",
    "    blended = Image.blend(img, texture, 0.5)\n",
    "\n",
    "    return blended\n",
    "\n",
    "def color_transform(img):\n",
    "    '''\n",
    "    Applies random color transformations to image\n",
    "    Parameters chosen to be within a realistic range similar to real world images\n",
    "    '''\n",
    "    transforms = v2.Compose([\n",
    "        v2.ColorJitter(brightness = (0.8, 1.2),  # small range as extreme lighting is not so present in real world\n",
    "                       contrast   = (0.8, 1.5),  # wider range as contrast occurs in more examples\n",
    "                       saturation = (0.8, 1.2),  # small range\n",
    "                       hue        = (-0.1, 0.1), # idk\n",
    "                       ),\n",
    "        v2.RandomPhotometricDistort(brightness = (0.8, 1.2),\n",
    "                                    contrast   = (0.7, 1.3),\n",
    "                                    saturation = (0.8, 1.2),\n",
    "                                    hue        = (-0.05, 0.05),\n",
    "                                    ),\n",
    "        v2.GaussianBlur(kernel_size=25, sigma=(0.1, 100.0)), # chance to blur a lot or a little - mostly an ok amount\n",
    "        # v2.RandomSolarize(0.5, 0.5), # NOT USED as it may interfere with binarizer learning and white on black is not common\n",
    "    ])\n",
    "\n",
    "    img = transforms(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "\"gen_imgs\" takes in params and uses helpers to synthesize both the ground truth and noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000\n",
      "100/10000\n",
      "200/10000\n",
      "300/10000\n",
      "400/10000\n",
      "500/10000\n",
      "600/10000\n",
      "700/10000\n",
      "800/10000\n",
      "900/10000\n",
      "1000/10000\n",
      "1100/10000\n",
      "1200/10000\n",
      "1300/10000\n",
      "1400/10000\n",
      "1500/10000\n",
      "1600/10000\n",
      "1700/10000\n",
      "1800/10000\n",
      "1900/10000\n",
      "2000/10000\n",
      "2100/10000\n",
      "2200/10000\n",
      "2300/10000\n",
      "2400/10000\n",
      "2500/10000\n",
      "2600/10000\n",
      "2700/10000\n",
      "2800/10000\n",
      "2900/10000\n",
      "3000/10000\n",
      "3100/10000\n",
      "3200/10000\n",
      "3300/10000\n",
      "3400/10000\n",
      "3500/10000\n",
      "3600/10000\n",
      "3700/10000\n",
      "3800/10000\n",
      "3900/10000\n",
      "4000/10000\n",
      "4100/10000\n",
      "4200/10000\n",
      "4300/10000\n",
      "4400/10000\n",
      "4500/10000\n",
      "4600/10000\n",
      "4700/10000\n",
      "4800/10000\n",
      "4900/10000\n",
      "5000/10000\n",
      "5100/10000\n",
      "5200/10000\n",
      "5300/10000\n",
      "5400/10000\n",
      "5500/10000\n",
      "5600/10000\n",
      "5700/10000\n",
      "5800/10000\n",
      "5900/10000\n",
      "6000/10000\n",
      "6100/10000\n",
      "6200/10000\n",
      "6300/10000\n",
      "6400/10000\n",
      "6500/10000\n",
      "6600/10000\n",
      "6700/10000\n",
      "6800/10000\n",
      "6900/10000\n",
      "7000/10000\n",
      "7100/10000\n",
      "7200/10000\n",
      "7300/10000\n",
      "7400/10000\n",
      "7500/10000\n",
      "7600/10000\n",
      "7700/10000\n",
      "7800/10000\n",
      "7900/10000\n",
      "8000/10000\n",
      "8100/10000\n",
      "8200/10000\n",
      "8300/10000\n",
      "8400/10000\n",
      "8500/10000\n",
      "8600/10000\n",
      "8700/10000\n",
      "8800/10000\n",
      "8900/10000\n",
      "9000/10000\n",
      "9100/10000\n",
      "9200/10000\n",
      "9300/10000\n",
      "9400/10000\n",
      "9500/10000\n",
      "9600/10000\n",
      "9700/10000\n",
      "9800/10000\n",
      "9900/10000\n"
     ]
    }
   ],
   "source": [
    "def gen_imgs(N_imgs, texture_path):\n",
    "    '''Generates N images'''\n",
    "    for i in range(N_imgs):\n",
    "\n",
    "        # generate string to encode into DMC\n",
    "        to_encode = gen_string()\n",
    "        dmc_img = encode_image(to_encode)\n",
    "        # dmc_img.show()\n",
    "        # break\n",
    "\n",
    "        # generate shape transformed DMC\n",
    "        shape_img = shape_transform(dmc_img)\n",
    "\n",
    "        # save ground truth image\n",
    "        ground_truth = shape_img.copy()\n",
    "        ground_truth.resize((1000, 1000), Image.BILINEAR)\n",
    "        ground_truth.save(f'../data/synth_data/ground_truth/{to_encode}.png')\n",
    "\n",
    "        # shape_img.show()\n",
    "        # break\n",
    "\n",
    "        # generate scaled DMC\n",
    "        increment = random.randint(1, 250)\n",
    "        scale_img = brightness_transform(shape_img, increment=increment)\n",
    "        # scale_img.show()\n",
    "        # break\n",
    "\n",
    "        # blend into metal texture\n",
    "        texture = f'{os.path.dirname(texture_path)}/{random.choice(os.listdir(texture_path))}'\n",
    "        blended_img = blend_texture(scale_img, texture)\n",
    "        # blended_img.show()\n",
    "        # break\n",
    "\n",
    "        # generate colored DMC\n",
    "        color_img = color_transform(blended_img)\n",
    "\n",
    "        # resize to size for binarizer\n",
    "        color_img = color_img.resize((1000, 1000), Image.BILINEAR)\n",
    "\n",
    "        # final sharpening to ground_truth image\n",
    "        # ground_truth = ground_truth.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "        # color_img.show()\n",
    "        # ground_truth.show()\n",
    "        # break\n",
    "\n",
    "        # save ground noisy image\n",
    "        color_img.save(f'../data/synth_data/noisy/{to_encode}.png')\n",
    "\n",
    "        # print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f'{i}/{N_imgs}')\n",
    "\n",
    "    return\n",
    "\n",
    "# on average, the size of a pair of color_img and ground_truth iamges are 600KB\n",
    "# so the total size of the dataset will be 10,000 * 600KB = 6,000,000KB = ~6GB\n",
    "\n",
    "# generates randomized imgs\n",
    "N_imgs = 10000\n",
    "gen_imgs(N_imgs, texture_path = '../data/textures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_imgs(N_strings, N_shapes, N_scalings, texture_path, N_colors):\n",
    "#     '''Generates parameters for N images to feed to the image generator'''\n",
    "#     print(f'Generating {N_strings * N_shapes * (N_scalings + 1) * N_colors * 2} images...')\n",
    "#     print('(N_strings * N_shapes * (N_scalings + 1) * N_colors * 2)')\n",
    "\n",
    "#     # generate N_strings DMCs\n",
    "#     for str1 in range(N_strings):\n",
    "#         to_encode = gen_string()\n",
    "#         dmc_img = encode_image(to_encode)\n",
    "#         # dmc_img.show()\n",
    "#         # break\n",
    "\n",
    "#         # generate N_shapes shape transformed DMCs of each DMC\n",
    "#         for str2 in range(N_shapes):\n",
    "#             shape_img = shape_transform(dmc_img)\n",
    "\n",
    "#             # save ground truth image\n",
    "#             ground_truth = shape_img.copy()\n",
    "#             ground_truth.resize((1000, 1000), Image.BILINEAR)\n",
    "#             ground_truth.save(f'../data/synth_data/ground_truth/{str1}_{str2}.png')\n",
    "\n",
    "#             # shape_img.show()\n",
    "#             # break\n",
    "\n",
    "#             # generate N_scalings scaled DMCs of each DMC\n",
    "#             # incremenets with N_scalings = 5: [0, 50, 100, 150, 200, 250]\n",
    "#             base = int(250 / N_scalings)\n",
    "#             increments = [base * i for i in range(N_scalings)]\n",
    "#             increments.append(250) # close to white (very pale DMC)\n",
    "#             for increment in increments:\n",
    "#                 str3 = increment\n",
    "#                 scale_img = brightness_transform(shape_img, increment=increment)\n",
    "#                 # scale_img.show()\n",
    "#                 # break\n",
    "\n",
    "#                 # blend into metal texture\n",
    "#                 blended_img = blend_texture(scale_img, texture_path)\n",
    "#                 # blended_img.show()\n",
    "#                 # break\n",
    "\n",
    "#                 # generate N_colors colored DMCs of each DMC\n",
    "#                 for str4 in range(N_colors):\n",
    "#                     color_img = color_transform(blended_img)\n",
    "\n",
    "#                     # resize to size for binarizer\n",
    "#                     color_img = color_img.resize((1000, 1000), Image.BILINEAR)\n",
    "\n",
    "#                     # final sharpening to ground_truth image\n",
    "#                     # ground_truth = ground_truth.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "#                     # color_img.show()\n",
    "#                     # ground_truth.show()\n",
    "#                     # break\n",
    "\n",
    "#                     # save ground noisy image\n",
    "#                     color_img.save(f'../data/synth_data/noisy/{str1}_{str2}_{str3}_{str4}.png')\n",
    "\n",
    "#     return\n",
    "\n",
    "# # with these parameters, we generate 12 * 12 * 6 * 12 * 2 = 20,736 images\n",
    "# # on average, the size of a pair of color_img and ground_truth iamges are 600KB\n",
    "# # so the total size of the dataset is 20,736/2 * 600KB = 10,368 * 600KB = 6,220,800KB = ~6.2GB\n",
    "# # which is a reasonable size for a dataset\n",
    "# gen_imgs(N_strings    = 500, # we want to generalize for many different DMCs\n",
    "#          N_shapes     = 10,    # we want to generalize for different shapes (but dont need that many)\n",
    "#          N_scalings   = 3,    # generates N_scalings + 1 for fades of DMCs\n",
    "#          texture_path = '../data/textures/',\n",
    "#          N_colors     = 1)   # We want to generalize for different colors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
