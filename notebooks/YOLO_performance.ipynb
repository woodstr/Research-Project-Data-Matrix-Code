{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools as it\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from pylibdmtx.pylibdmtx import decode\n",
    "from ultralytics import YOLO, settings\n",
    "root_dir = os.getcwd().replace('\\\\notebooks', '')\n",
    "settings.update({'datasets_dir': f'{root_dir}/data/processed/test', 'runs_dir': f'{root_dir}/yolo/runs'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image printing/saving helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_save_imgs(imgs, titles, eval):\n",
    "    '''Organizes images into a grid and saves to figures folder'''\n",
    "\n",
    "    fig, axs = plt.subplots(len(imgs), 1, figsize=(5, 10))\n",
    "    for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title(title)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    fig.savefig(f'../figures/{eval}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(imgs, titles, dir):\n",
    "    '''Saves images with titles to given directory'''\n",
    "\n",
    "    for img, title in zip(imgs, titles):\n",
    "        cv2.imwrite(f'{dir}/{title}.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_baseline(glob_path):\n",
    "    '''\n",
    "    Runs baseline decoder and counts the number of decodings\n",
    "    '''\n",
    "    img_paths = glob.glob(glob_path)\n",
    "\n",
    "    # stat tracking\n",
    "    num_decodings = 0\n",
    "    num_valid_decodings = 0\n",
    "\n",
    "    imgs = []\n",
    "    titles = []\n",
    "\n",
    "    failure_cases = []\n",
    "    success_cases = []\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        decodings = decode(img)\n",
    "\n",
    "        actual_decoding = os.path.basename(img_path).split('_')[0]\n",
    "        actual_decoding = actual_decoding.replace('-', '')\n",
    "\n",
    "        # fixing some actual decodings\n",
    "        if actual_decoding == 'KV8INMEP':\n",
    "            actual_decoding = '#D1FPE50HA9NS0047XG264##KV8INMEP'\n",
    "        elif actual_decoding == 'KW8PXY3D':\n",
    "            actual_decoding = '#D1FPE50HA9NS0047XG264##KW8PXY3D'\n",
    "\n",
    "        if decodings is not None and len(decodings) > 0:\n",
    "            num_decodings += 1\n",
    "\n",
    "            for decoding in decodings:\n",
    "                decoded_string = decoding.data.decode('utf-8')\n",
    "\n",
    "                if decoded_string == actual_decoding:\n",
    "                    print(f'Valid decoding! {actual_decoding}')\n",
    "                    num_valid_decodings += 1\n",
    "                    imgs.append(img)\n",
    "                    titles.append(actual_decoding)\n",
    "                    success_cases.append((img, actual_decoding))\n",
    "                else:\n",
    "                    print('Invalid decoding!')\n",
    "                    print(actual_decoding)\n",
    "                    print(decoded_string)\n",
    "        else: # no decodings\n",
    "            failure_cases.append((img, actual_decoding))\n",
    "\n",
    "    # calculate stats\n",
    "    dm_decode_rate = num_decodings/len(img_paths)\n",
    "    valid_decode_rate = num_valid_decodings/len(img_paths)\n",
    "\n",
    "    # save stat images for later inspection\n",
    "    save_images([img for img, _ in failure_cases], [title for _, title in failure_cases], '../data/stats/failures/baseline')\n",
    "    save_images([img for img, _ in success_cases], [title for _, title in success_cases], '../data/stats/successes/baseline')\n",
    "\n",
    "    print()\n",
    "    print(f'{num_valid_decodings}/{len(img_paths)}')\n",
    "    print(f'Dm decode rate: {dm_decode_rate}')\n",
    "    print(f'Valid decode rate: {valid_decode_rate}')\n",
    "    print_save_imgs(imgs, titles, 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_map(model, eval_yaml):\n",
    "    '''\n",
    "    Runs ultralytics val function to get mAP score and other metrics\n",
    "    '''\n",
    "    metrics = model.val(data=eval_yaml, split='test')\n",
    "\n",
    "    print()\n",
    "    print(f'Precision : {round(metrics.box.p[0], 2)}')  # close to 1 is good\n",
    "    print(f'Recall    : {round(metrics.box.r[0], 2)}')  # close to 1 is good\n",
    "    print(f'F1        : {round(metrics.box.f1[0], 2)}') # close to 1 is good\n",
    "    print(f'mAP50-95  : {round(metrics.box.map, 3)}')   # 0.3 can be good, higher is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_decoding(model, glob_path, fig_title):\n",
    "    '''\n",
    "    Performs cropping and decoding of the images\n",
    "    '''\n",
    "    img_paths = glob.glob(glob_path)\n",
    "\n",
    "    # stat tracking\n",
    "    num_decodings = 0\n",
    "    num_valid_decodings = 0\n",
    "\n",
    "    imgs = []\n",
    "    titles = []\n",
    "\n",
    "    idx = 0\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        results = model(img)\n",
    "        boxes = results[0].boxes.xyxy.tolist()\n",
    "\n",
    "        actual_decoding = os.path.basename(img_path).split('_')[0]\n",
    "        actual_decoding = actual_decoding.replace('-', '') # minor cleaning\n",
    "\n",
    "        # fixing some actual decodings\n",
    "        if actual_decoding == 'KV8INMEP':\n",
    "            actual_decoding = '#D1FPE50HA9NS0047XG264##KV8INMEP'\n",
    "        elif actual_decoding == 'KW8PXY3D':\n",
    "            actual_decoding = '#D1FPE50HA9NS0047XG264##KW8PXY3D'\n",
    "\n",
    "        if boxes != None and len(boxes) > 0:\n",
    "            # only look at box with highest confidence\n",
    "            box = boxes[0]\n",
    "\n",
    "            # crop with some padding (to not have too small of a crop)\n",
    "            pad = 10\n",
    "            crop_obj = img[max(0, int(box[1])-pad):max(0, int(box[3])+pad), max(0, int(box[0])-pad):max(0, int(box[2])+pad)]\n",
    "            decodings = decode(crop_obj)\n",
    "\n",
    "            if decodings != None and len(decodings) > 0:\n",
    "                num_decodings += 1\n",
    "\n",
    "                for decoding in decodings:\n",
    "                    decoded_string = decoding.data.decode('utf-8')\n",
    "                    \n",
    "                    if decoded_string == actual_decoding:\n",
    "                        print(f'Valid decoding! {actual_decoding}')\n",
    "                        num_valid_decodings += 1\n",
    "                        imgs.append(crop_obj)\n",
    "                        titles.append(actual_decoding)\n",
    "                    else:\n",
    "                        print('Invalid decoding!')\n",
    "                        print(actual_decoding)\n",
    "                        print(decoded_string)\n",
    "\n",
    "            # optional saving\n",
    "            cv2.imwrite(f'../data/cropped/{actual_decoding}-{idx}.jpg', crop_obj)\n",
    "            idx += 1\n",
    "\n",
    "    # calculate stats\n",
    "    dm_decode_rate = num_decodings/len(img_paths)\n",
    "    valid_decode_rate = num_valid_decodings/len(img_paths)\n",
    "\n",
    "    print()\n",
    "    print(f'{num_valid_decodings}/{len(img_paths)}')\n",
    "    print(f'Dm decode rate: {dm_decode_rate}')\n",
    "    print(f'Valid decode rate: {valid_decode_rate}')\n",
    "    print_save_imgs(imgs, titles, fig_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_yolo(model_path, glob_path, eval_yaml, fig_title):\n",
    "    '''\n",
    "    Given a yolo model, makes the following evaluations:\n",
    "     - mAP scores for bounding boxes\n",
    "     - DM decode rate (% of decodings of test images)\n",
    "     - Valid DM decode rate (% of decodings of test images that match with the serial number)\n",
    "    Also prints the first \"print_count\" images with predictions.\n",
    "    '''\n",
    "    # Load the model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # mAP scores (saves to runs dir)\n",
    "    eval_map(model, eval_yaml)\n",
    "\n",
    "    # Crop and decode\n",
    "    crop_decoding(model, glob_path, fig_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat eval\n",
    "\n",
    "For running statistics on the .csv files saved under ../data/stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(csv_path):\n",
    "\n",
    "    # Load the csv\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     usecols=['Case', 'Code Color', 'Background Color', 'Type', 'distortions'],\n",
    "                     dtype={'Case': str, 'Code Color': str, 'Background Color': str, 'Type': str, 'distortions': str})\n",
    "\n",
    "    # Calculate basic stats\n",
    "    sns.set_theme()\n",
    "    # sns.countplot(x='Code Color', data=df);plt.show()\n",
    "    # sns.countplot(x='Background Color', data=df);plt.show()\n",
    "\n",
    "    # Count of common color combinations\n",
    "    df['Color Combo'] = df['Code Color'] + ' ' + df['Background Color']\n",
    "    sns.countplot(x='Color Combo', data=df);plt.show()\n",
    "    sns.countplot(x='Type', data=df);plt.show()\n",
    "\n",
    "    # Count of distortions\n",
    "    distortions = df['distortions'].unique().tolist()\n",
    "    distortions.remove(np.nan)\n",
    "\n",
    "    unique_distortions = {}\n",
    "    for distortion in distortions:\n",
    "        split = distortion.split(';')\n",
    "        for s in split:\n",
    "            if s not in unique_distortions:\n",
    "                unique_distortions[s] = 1\n",
    "            else:\n",
    "                unique_distortions[s] += 1\n",
    "\n",
    "    distortion_cols = {}\n",
    "    for distortion in unique_distortions:\n",
    "        distortion_cols[distortion] = []\n",
    "    for _, row in df.iterrows():\n",
    "        distortions = row['distortions']\n",
    "        if pd.isna(distortions):\n",
    "            for distortion in distortion_cols:\n",
    "                distortion_cols[distortion].append(0)\n",
    "            continue\n",
    "        split = distortions.split(';')\n",
    "        for distortion in distortion_cols:\n",
    "            if distortion in split:\n",
    "                distortion_cols[distortion].append(1)\n",
    "            else:\n",
    "                distortion_cols[distortion].append(0)\n",
    "    for distortion in distortion_cols:\n",
    "        df[distortion] = distortion_cols[distortion]\n",
    "\n",
    "    sorted_ = df[distortion_cols.keys()].sum().sort_values(ascending=False)\n",
    "    sns.barplot(x=sorted_, y=sorted_.keys());plt.xlabel('Count');plt.ylabel('');plt.show()\n",
    "\n",
    "calc_stats('../data/stats/baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_baseline('../data/MAN/images/test/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_yolo('../yolo/models/kaggle_scratch.pt', '../data/MAN/images/test/*.jpg', '../data/MAN/data.yaml', 'Kaggle Scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_yolo('../yolo/models/kaggle_finetuned.pt', '../data/MAN/images/test/*.jpg', '../data/MAN/data.yaml', 'Kaggle Finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultralytics finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_yolo('../yolo/models/ultralytics_finetuned.pt', '../data/MAN/images/test/*.jpg', '../data/MAN/data.yaml', 'Ultralytics Finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
