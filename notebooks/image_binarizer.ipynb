{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMCDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None, mask_transform=None):\n",
    "        '''\n",
    "        '''\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        # print('Dataloader initialized')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image and mask\n",
    "        # print('Loading image:', self.image_paths[idx])\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "        # print('Images loaded')\n",
    "\n",
    "        # Convert both image and mask to tensors, apply any specified transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        # print('Images transformed to tensors')\n",
    "\n",
    "        # Ensure mask is a binary tensor (0 or 1 values)\n",
    "        # mask = (mask > 0.5).float() # Threshold mask to binary if not already\n",
    "\n",
    "        # print('Mask thresholded')\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize((512, 512), interpolation=InterpolationMode.BILINEAR), # Resize to match model input\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ResNet normalization\n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.Resize((512, 512), interpolation=InterpolationMode.BILINEAR), # Resize to match model input\n",
    "    v2.Grayscale(num_output_channels=1), # ensure mask is grayscale\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "test_size = 100\n",
    "batch_size = 4\n",
    "\n",
    "# Get paths to all images and masks\n",
    "train_image_paths = glob.glob('../data/synth_data/noisy/*.png')[:train_size]\n",
    "train_mask_paths = glob.glob('../data/synth_data/ground_truth/*.png')[:train_size]\n",
    "\n",
    "test_image_paths = glob.glob('../data/synth_data/noisy/*.png')[-test_size:]\n",
    "test_mask_paths = glob.glob('../data/synth_data/ground_truth/*.png')[-test_size:]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = DMCDataset(train_image_paths, train_mask_paths, transform=transform, mask_transform=mask_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = DMCDataset(test_image_paths, test_mask_paths, transform=transform, mask_transform=mask_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n",
      "torch.Size([4, 3, 512, 512]) torch.Size([4, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# train dataset example\n",
    "for i, (image, mask) in enumerate(train_dataset):\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n",
    "\n",
    "# train Dataloader example\n",
    "for i, (image, mask) in enumerate(train_dataloader):\n",
    "    print(image.shape, mask.shape)\n",
    "    image = v2.ToPILImage()(image[0].squeeze(0))\n",
    "    # image.show()\n",
    "\n",
    "    mask = v2.ToPILImage()(mask[0].squeeze(0))\n",
    "    # mask.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n",
      "torch.Size([4, 3, 512, 512]) torch.Size([4, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# test dataset example\n",
    "for i, (image, mask) in enumerate(test_dataset):\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n",
    "\n",
    "# test Dataloader example\n",
    "for i, (image, mask) in enumerate(test_dataloader):\n",
    "    print(image.shape, mask.shape)\n",
    "    image = v2.ToPILImage()(image[0].squeeze(0))\n",
    "    image.show()\n",
    "\n",
    "    mask = v2.ToPILImage()(mask[0].squeeze(0))\n",
    "    mask.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binarizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binarizer, self).__init__()\n",
    "\n",
    "        # Load the pretrained ResNet-18 model\n",
    "        resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "        # Use the ResNet layers up to the last layer (remove the fully connected layer)\n",
    "        self.encoder = nn.Sequential(*list(resnet18.children())[:-2]) # output size = 512 x 8 x 8\n",
    "\n",
    "        # Define the decoder part to upsample back to 512 x 512\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid() # Use sigmoid for binary output in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Pass input through the resnet-18 encoder and custom decoder'''\n",
    "        # print('FORWARD A')\n",
    "        x = self.encoder(x)\n",
    "        # print('FORWARD B')\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model = binarizer().to(device)\n",
    "\n",
    "# params\n",
    "lr = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - balances between two methods\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        smooth = 1.0  # To avoid division by zero\n",
    "        output = output.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        intersection = (output * target).sum()\n",
    "        dice = (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=1, dice_weight=1):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        bce_loss = self.bce(output, target)\n",
    "        dice_loss = self.dice(output, target)\n",
    "        return self.bce_weight * bce_loss + self.dice_weight * dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider:\n",
    "- adding early stopping so that we can increase epochs to a huge amount and leave running\n",
    "- use more of the dataset (90/10 train/test split?)\n",
    "- tweaking params (weight DMC restoration more than background denoising?)\n",
    "- replace nn.BCEWithLogitsLoss with BCELoss as sigmoid layer redundant\n",
    "- Look into weight argument of BCELoss, can we weigh dark pixels more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2312\n",
      "Epoch [2/10], Loss: 0.1757\n",
      "Epoch [3/10], Loss: 0.1752\n",
      "Epoch [4/10], Loss: 0.1734\n",
      "Epoch [5/10], Loss: 0.1721\n",
      "Epoch [6/10], Loss: 0.1714\n",
      "Epoch [7/10], Loss: 0.1711\n",
      "Epoch [8/10], Loss: 0.1708\n",
      "Epoch [9/10], Loss: 0.1705\n",
      "Epoch [10/10], Loss: 0.1703\n"
     ]
    }
   ],
   "source": [
    "# Actual training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # print('EPOCH', epoch)\n",
    "    model.train()\n",
    "    # print('ok')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    count = 0\n",
    "    for inputs, masks in train_dataloader: # consider renaming masks to targets\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "        # print('forward pass')\n",
    "        # Forward pass\n",
    "        outputs = model(inputs) # Add batch dimension to input\n",
    "\n",
    "        # print('loss calculate')\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # print('backwards pass')\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        count += batch_size\n",
    "        print(f'{count}/{train_size}', end='\\r')\n",
    "\n",
    "        # if count >= 10:\n",
    "            # break\n",
    "    # break\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output range: min=3.484792654383367e-24, max=1.0\n",
      "Output range after binarization: min=0.0, max=1.0\n",
      "Mean IoU: 0.2467\n",
      "Mean Dice Coefficient: 0.2483\n",
      "Mean Pixel Accuracy: 0.2445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24670674264431, 0.2483392882347107, 0.24445390701293945)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a test DataLoader providing (images, ground_truth_masks)\n",
    "def evaluate_model(model, test_loader, threshold=0.5):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    iou_total = 0\n",
    "    dice_total = 0\n",
    "    accuracy_total = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "        for images, ground_truths in test_loader:\n",
    "            # Move data to the same device as the model\n",
    "            images = images.to(device)\n",
    "            ground_truths = ground_truths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Binarize the outputs\n",
    "            predictions = (outputs > threshold).float() # Binarize predictions\n",
    "\n",
    "            # predictions = outputs # inspect the output pre binarization\n",
    "\n",
    "            # Calculate IoU\n",
    "            intersection = (predictions * ground_truths).sum((1, 2, 3))\n",
    "            union = (predictions + ground_truths).sum((1, 2, 3)) - intersection\n",
    "            iou = (intersection / union).mean()  # Mean IoU for batch\n",
    "            iou_total += iou.item()\n",
    "\n",
    "            # Calculate Dice Coefficient\n",
    "            dice = (2 * intersection / (predictions.sum((1, 2, 3)) + ground_truths.sum((1, 2, 3)))).mean()\n",
    "            dice_total += dice.item()\n",
    "\n",
    "            # Calculate Pixel Accuracy\n",
    "            correct = (predictions == ground_truths).float().sum()\n",
    "            accuracy = correct / ground_truths.numel()\n",
    "            accuracy_total += accuracy.item()\n",
    "\n",
    "            count += batch_size\n",
    "            print(f'{count}/{test_size}', end='\\r')\n",
    "\n",
    "            if count >= 100:\n",
    "                break\n",
    "\n",
    "    # debug print\n",
    "    print(f'Output range: min={outputs.min().item()}, max={outputs.max().item()}')\n",
    "    print(f'Output range after binarization: min={predictions.min().item()}, max={predictions.max().item()}')\n",
    "\n",
    "    # Average the metrics over the whole test set\n",
    "    mean_iou = iou_total / count\n",
    "    mean_dice = dice_total / count\n",
    "    mean_accuracy = accuracy_total / count\n",
    "\n",
    "    print(f'Mean IoU: {mean_iou:.4f}')\n",
    "    print(f'Mean Dice Coefficient: {mean_dice:.4f}')\n",
    "    print(f'Mean Pixel Accuracy: {mean_accuracy:.4f}')\n",
    "\n",
    "    # show a few examples\n",
    "    for i in range(1):\n",
    "        image = v2.ToPILImage()(images[i].squeeze(0))\n",
    "        mask = v2.ToPILImage()(ground_truths[i].squeeze(0))\n",
    "        pred = v2.ToPILImage()(predictions[i].squeeze(0))\n",
    "        # image.show()\n",
    "        # time.sleep(1)\n",
    "        # mask.show()\n",
    "        # time.sleep(1)\n",
    "        # pred.show()\n",
    "\n",
    "        image.save('../figures/binarization/failure_noisy.png')\n",
    "        mask.save('../figures/binarization/failure_ground_truth.png')\n",
    "        pred.save('../figures/binarization/failure_prediction.png')\n",
    "\n",
    "    return mean_iou, mean_dice, mean_accuracy\n",
    "\n",
    "evaluate_model(model, test_dataloader, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
