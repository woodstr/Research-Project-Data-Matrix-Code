{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMCDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None, mask_transform=None):\n",
    "        '''\n",
    "        '''\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        # print('Dataloader initialized')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image and mask\n",
    "        # print('Loading image:', self.image_paths[idx])\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "        # print('Images loaded')\n",
    "    \n",
    "        # Convert both image and mask to tensors, apply any specified transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        # print('Images transformed to tensors')\n",
    "        \n",
    "        # Ensure mask is a binary tensor (0 or 1 values)\n",
    "        # mask = (mask > 0.5).float() # Threshold mask to binary if not already\n",
    "\n",
    "        # print('Mask thresholded')\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize((512, 512), interpolation=InterpolationMode.BILINEAR), # Resize to match model input\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ResNet normalization\n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.Resize((512, 512), interpolation=InterpolationMode.BILINEAR), # Resize to match model input\n",
    "    v2.Grayscale(num_output_channels=1), # ensure mask is grayscale\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to all images and masks\n",
    "train_image_paths = glob.glob('../data/synth_data/noisy/*.png')[:500]\n",
    "train_mask_paths = glob.glob('../data/synth_data/ground_truth/*.png')[:500]\n",
    "\n",
    "test_image_paths = glob.glob('../data/synth_data/noisy/*.png')[-500:]\n",
    "test_mask_paths = glob.glob('../data/synth_data/ground_truth/*.png')[-500:]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = DMCDataset(train_image_paths, train_mask_paths, transform=transform, mask_transform=mask_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n",
    "test_dataset = DMCDataset(test_image_paths, test_mask_paths, transform=transform, mask_transform=mask_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset example\n",
    "for i, (image, mask) in enumerate(train_dataset):\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n",
    "\n",
    "# train Dataloader example\n",
    "for i, (image, mask) in enumerate(train_dataloader):\n",
    "    print(image.shape, mask.shape)\n",
    "    image = v2.ToPILImage()(image[0].squeeze(0))\n",
    "    # image.show()\n",
    "\n",
    "    mask = v2.ToPILImage()(mask[0].squeeze(0))\n",
    "    # mask.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset example\n",
    "for i, (image, mask) in enumerate(test_dataset):\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n",
    "\n",
    "# test Dataloader example\n",
    "for i, (image, mask) in enumerate(test_dataloader):\n",
    "    print(image.shape, mask.shape)\n",
    "    image = v2.ToPILImage()(image[0].squeeze(0))\n",
    "    image.show()\n",
    "\n",
    "    mask = v2.ToPILImage()(mask[0].squeeze(0))\n",
    "    mask.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binarizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binarizer, self).__init__()\n",
    "\n",
    "        # Load the pretrained ResNet-18 model\n",
    "        resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "        # Use the ResNet layers up to the last layer (remove the fully connected layer)\n",
    "        self.encoder = nn.Sequential(*list(resnet18.children())[:-2]) # output size = 512 x 8 x 8\n",
    "\n",
    "        # Define the decoder part to upsample back to 256x256\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            # nn.Conv2d(16, 1, kernel_size=1), # Output layer with 1 channel for binary mask\n",
    "            nn.Sigmoid() # Use sigmoid for binary output in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Pass input through the resnet-18 encoder and custom decoder'''\n",
    "        # print('FORWARD A')\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        x = self.encoder(x)\n",
    "        # print('FORWARD B')\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model = binarizer().to(device)\n",
    "\n",
    "# params\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # print('EPOCH', epoch)\n",
    "    model.train()\n",
    "    # print('ok')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    count = 0\n",
    "    for inputs, masks in train_dataloader: # consider renaming masks to targets\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "        # print('forward pass')\n",
    "        # Forward pass\n",
    "        outputs = model(inputs) # Add batch dimension to input\n",
    "\n",
    "        # print('loss calculate')\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # print('backwards pass')\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        count += 1\n",
    "        print(count, end='\\r')\n",
    "\n",
    "        if count == 10:\n",
    "            break\n",
    "    break\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a test DataLoader providing (images, ground_truth_masks)\n",
    "def evaluate_model(model, test_loader, threshold=0.5):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    iou_total = 0\n",
    "    dice_total = 0\n",
    "    accuracy_total = 0\n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "        for images, ground_truths in test_loader:\n",
    "            # Move data to the same device as the model\n",
    "            images = images.to(device)\n",
    "            ground_truths = ground_truths.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            predictions = (outputs > threshold).float()  # Binarize predictions\n",
    "            # predictions = outputs # inspect the output pre binarization\n",
    "            \n",
    "            # Calculate IoU\n",
    "            intersection = (predictions * ground_truths).sum((1, 2, 3))\n",
    "            union = (predictions + ground_truths).sum((1, 2, 3)) - intersection\n",
    "            iou = (intersection / union).mean()  # Mean IoU for batch\n",
    "            iou_total += iou.item()\n",
    "            \n",
    "            # Calculate Dice Coefficient\n",
    "            dice = (2 * intersection / (predictions.sum((1, 2, 3)) + ground_truths.sum((1, 2, 3)))).mean()\n",
    "            dice_total += dice.item()\n",
    "            \n",
    "            # Calculate Pixel Accuracy\n",
    "            correct = (predictions == ground_truths).float().sum()\n",
    "            accuracy = correct / ground_truths.numel()\n",
    "            accuracy_total += accuracy.item()\n",
    "            \n",
    "            count += 1\n",
    "            print(count, end='\\r')\n",
    "\n",
    "            if count == 10:\n",
    "                # show a few examples\n",
    "                for i in range(1):\n",
    "                    image = v2.ToPILImage()(images[i].squeeze(0))\n",
    "                    mask = v2.ToPILImage()(ground_truths[i].squeeze(0))\n",
    "                    pred = v2.ToPILImage()(predictions[i].squeeze(0))\n",
    "                    image.show()\n",
    "                    mask.show()\n",
    "                    pred.show()\n",
    "                break\n",
    "    \n",
    "    # Average the metrics over the whole test set\n",
    "    mean_iou = iou_total / count\n",
    "    mean_dice = dice_total / count\n",
    "    mean_accuracy = accuracy_total / count\n",
    "    \n",
    "    print(f'Mean IoU: {mean_iou:.4f}')\n",
    "    print(f'Mean Dice Coefficient: {mean_dice:.4f}')\n",
    "    print(f'Mean Pixel Accuracy: {mean_accuracy:.4f}')\n",
    "    \n",
    "    return mean_iou, mean_dice, mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
